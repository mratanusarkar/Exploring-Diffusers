{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWZRdApH8ike"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/diffusers/sdxl-compel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXUhvzsM8ikj"
      },
      "source": [
        "# Prompt Weighing and Blending using for SDXL 1.0 using [Compel](https://github.com/damian0815/compel) and [ðŸ§¨ Diffusers](https://huggingface.co/docs/diffusers)\n",
        "\n",
        "\n",
        "This notebook demonstrates the following:\n",
        "- Performing text-conditional image-generations using [ðŸ§¨ Diffusers](https://huggingface.co/docs/diffusers).\n",
        "- Using the Stable Diffusion XL Refiner pipeline to further refine the outputs of the base model.\n",
        "- Manage image generation experiments using [Weights & Biases](http://wandb.ai/geekyrakshit).\n",
        "- Log the prompts and generated images to [Weigts & Biases](http://wandb.ai/geekyrakshit) for visalization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5lb1akQ8ikk"
      },
      "source": [
        "## Installing the Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "djlMK4pI8ikl"
      },
      "outputs": [],
      "source": [
        "# !pip install -qq diffusers[\"torch\"] transformers compel wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zCS8LgF88ikm"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'scipy'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwandb\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdiffusers\u001b[39;00m \u001b[39mimport\u001b[39;00m DiffusionPipeline, EulerDiscreteScheduler\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcompel\u001b[39;00m \u001b[39mimport\u001b[39;00m Compel, ReturnedEmbeddingsType\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrandom\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/diffusers/lib/python3.10/site-packages/diffusers/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m0.20.0.dev0\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconfiguration_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m ConfigMixin\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      5\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[1;32m      6\u001b[0m     is_flax_available,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     logging,\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/anaconda3/envs/diffusers/lib/python3.10/site-packages/diffusers/configuration_utils.py:34\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrequests\u001b[39;00m \u001b[39mimport\u001b[39;00m HTTPError\n\u001b[1;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__\n\u001b[0;32m---> 34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     35\u001b[0m     DIFFUSERS_CACHE,\n\u001b[1;32m     36\u001b[0m     HUGGINGFACE_CO_RESOLVE_ENDPOINT,\n\u001b[1;32m     37\u001b[0m     DummyObject,\n\u001b[1;32m     38\u001b[0m     deprecate,\n\u001b[1;32m     39\u001b[0m     extract_commit_hash,\n\u001b[1;32m     40\u001b[0m     http_user_agent,\n\u001b[1;32m     41\u001b[0m     logging,\n\u001b[1;32m     42\u001b[0m )\n\u001b[1;32m     45\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mget_logger(\u001b[39m__name__\u001b[39m)\n\u001b[1;32m     47\u001b[0m _re_configuration_file \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39mcompile(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mconfig\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m.(.*)\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m.json\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/envs/diffusers/lib/python3.10/site-packages/diffusers/utils/__init__.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpackaging\u001b[39;00m \u001b[39mimport\u001b[39;00m version\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__\n\u001b[0;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39maccelerate_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m apply_forward_hook\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconstants\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     CONFIG_NAME,\n\u001b[1;32m     24\u001b[0m     DEPRECATED_REVISION_ARGS,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     WEIGHTS_NAME,\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdeprecation_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m deprecate\n",
            "File \u001b[0;32m~/anaconda3/envs/diffusers/lib/python3.10/site-packages/diffusers/utils/accelerate_utils.py:24\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mimport_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m is_accelerate_available\n\u001b[1;32m     23\u001b[0m \u001b[39mif\u001b[39;00m is_accelerate_available():\n\u001b[0;32m---> 24\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39maccelerate\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_forward_hook\u001b[39m(method):\n\u001b[1;32m     28\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39m    Decorator that applies a registered CpuOffload hook to an arbitrary function rather than `forward`. This is useful\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m    for cases where a PyTorch module provides functions other than `forward` that should trigger a move to the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39m    :param method: The method to decorate. This method should be a method of a PyTorch module.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/diffusers/lib/python3.10/site-packages/accelerate/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m0.21.0\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39maccelerator\u001b[39;00m \u001b[39mimport\u001b[39;00m Accelerator\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbig_modeling\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      5\u001b[0m     cpu_offload,\n\u001b[1;32m      6\u001b[0m     cpu_offload_with_hook,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     load_checkpoint_and_dispatch,\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m skip_first_batches\n",
            "File \u001b[0;32m~/anaconda3/envs/diffusers/lib/python3.10/site-packages/accelerate/accelerator.py:35\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhooks\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mhooks\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcheckpointing\u001b[39;00m \u001b[39mimport\u001b[39;00m load_accelerator_state, load_custom_state, save_accelerator_state, save_custom_state\n\u001b[1;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoaderDispatcher, prepare_data_loader, skip_first_batches\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlogging\u001b[39;00m \u001b[39mimport\u001b[39;00m get_logger\n",
            "File \u001b[0;32m~/anaconda3/envs/diffusers/lib/python3.10/site-packages/accelerate/checkpointing.py:24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcuda\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mamp\u001b[39;00m \u001b[39mimport\u001b[39;00m GradScaler\n\u001b[0;32m---> 24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     25\u001b[0m     MODEL_NAME,\n\u001b[1;32m     26\u001b[0m     OPTIMIZER_NAME,\n\u001b[1;32m     27\u001b[0m     RNG_STATE_NAME,\n\u001b[1;32m     28\u001b[0m     SCALER_NAME,\n\u001b[1;32m     29\u001b[0m     SCHEDULER_NAME,\n\u001b[1;32m     30\u001b[0m     get_pretty_name,\n\u001b[1;32m     31\u001b[0m     is_tpu_available,\n\u001b[1;32m     32\u001b[0m     is_xpu_available,\n\u001b[1;32m     33\u001b[0m     save,\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     37\u001b[0m \u001b[39mif\u001b[39;00m is_tpu_available(check_device\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     38\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtorch_xla\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mxla_model\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mxm\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/diffusers/lib/python3.10/site-packages/accelerate/utils/__init__.py:131\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mif\u001b[39;00m is_deepspeed_available():\n\u001b[1;32m    122\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdeepspeed\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m    123\u001b[0m         DeepSpeedEngineWrapper,\n\u001b[1;32m    124\u001b[0m         DeepSpeedOptimizerWrapper,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m         HfDeepSpeedConfig,\n\u001b[1;32m    129\u001b[0m     )\n\u001b[0;32m--> 131\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbnb\u001b[39;00m \u001b[39mimport\u001b[39;00m has_4bit_bnb_layers, load_and_quantize_model\n\u001b[1;32m    132\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfsdp_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m load_fsdp_model, load_fsdp_optimizer, save_fsdp_model, save_fsdp_optimizer\n\u001b[1;32m    133\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlaunch\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m    134\u001b[0m     PrepareForLaunch,\n\u001b[1;32m    135\u001b[0m     _filter_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m     prepare_tpu,\n\u001b[1;32m    141\u001b[0m )\n",
            "File \u001b[0;32m~/anaconda3/envs/diffusers/lib/python3.10/site-packages/accelerate/utils/bnb.py:42\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodeling\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     32\u001b[0m     find_tied_parameters,\n\u001b[1;32m     33\u001b[0m     get_balanced_memory,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     set_module_tensor_to_device,\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     41\u001b[0m \u001b[39mif\u001b[39;00m is_bnb_available():\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mbnb\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcopy\u001b[39;00m \u001b[39mimport\u001b[39;00m deepcopy\n\u001b[1;32m     47\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mgetLogger(\u001b[39m__name__\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/envs/diffusers/lib/python3.10/site-packages/bitsandbytes/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m cuda_setup, utils, research\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mautograd\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_functions\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     MatmulLtState,\n\u001b[1;32m      9\u001b[0m     bmm_cublas,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     matmul_4bit\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcextension\u001b[39;00m \u001b[39mimport\u001b[39;00m COMPILED_WITH_CUDA\n",
            "File \u001b[0;32m~/anaconda3/envs/diffusers/lib/python3.10/site-packages/bitsandbytes/research/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m nn\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mautograd\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_functions\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     switchback_bnb,\n\u001b[1;32m      4\u001b[0m     matmul_fp8_global,\n\u001b[1;32m      5\u001b[0m     matmul_fp8_mixed,\n\u001b[1;32m      6\u001b[0m )\n",
            "File \u001b[0;32m~/anaconda3/envs/diffusers/lib/python3.10/site-packages/bitsandbytes/research/nn/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodules\u001b[39;00m \u001b[39mimport\u001b[39;00m LinearFP8Mixed, LinearFP8Global\n",
            "File \u001b[0;32m~/anaconda3/envs/diffusers/lib/python3.10/site-packages/bitsandbytes/research/nn/modules.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m Tensor, device, dtype, nn\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mbnb\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptim\u001b[39;00m \u001b[39mimport\u001b[39;00m GlobalOptimManager\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m OutlierTracer, find_outlier_dims\n\u001b[1;32m     11\u001b[0m T \u001b[39m=\u001b[39m TypeVar(\u001b[39m\"\u001b[39m\u001b[39mT\u001b[39m\u001b[39m\"\u001b[39m, bound\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtorch.nn.Module\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/envs/diffusers/lib/python3.10/site-packages/bitsandbytes/optim/__init__.py:8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcextension\u001b[39;00m \u001b[39mimport\u001b[39;00m COMPILED_WITH_CUDA\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39madagrad\u001b[39;00m \u001b[39mimport\u001b[39;00m Adagrad, Adagrad8bit, Adagrad32bit\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39madam\u001b[39;00m \u001b[39mimport\u001b[39;00m Adam, Adam8bit, Adam32bit, PagedAdam, PagedAdam8bit, PagedAdam32bit\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39madamw\u001b[39;00m \u001b[39mimport\u001b[39;00m AdamW, AdamW8bit, AdamW32bit, PagedAdamW, PagedAdamW8bit, PagedAdamW32bit\n",
            "File \u001b[0;32m~/anaconda3/envs/diffusers/lib/python3.10/site-packages/bitsandbytes/optim/adagrad.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizer\u001b[39;00m \u001b[39mimport\u001b[39;00m Optimizer1State\n\u001b[1;32m      8\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mAdagrad\u001b[39;00m(Optimizer1State):\n\u001b[1;32m      9\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     10\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m     11\u001b[0m         params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m         block_wise\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     22\u001b[0m     ):\n",
            "File \u001b[0;32m~/anaconda3/envs/diffusers/lib/python3.10/site-packages/bitsandbytes/optim/optimizer.py:12\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mitertools\u001b[39;00m \u001b[39mimport\u001b[39;00m chain\n\u001b[1;32m     10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mMockArgs\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, initial_data):\n",
            "File \u001b[0;32m~/anaconda3/envs/diffusers/lib/python3.10/site-packages/bitsandbytes/functional.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mitertools\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmath\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstats\u001b[39;00m \u001b[39mimport\u001b[39;00m norm\n\u001b[1;32m     13\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfunctools\u001b[39;00m \u001b[39mimport\u001b[39;00m reduce  \u001b[39m# Required in Python 3\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import wandb\n",
        "from diffusers import DiffusionPipeline, EulerDiscreteScheduler\n",
        "from compel import Compel, ReturnedEmbeddingsType\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJJ5DTPm8ikn"
      },
      "source": [
        "## Experiment Management using Weights & Biases\n",
        "\n",
        "Managing our image generation experiments is crucial for the sake of reproducibility. Hence we sync all the configs of our experiments with our Weights & Biases run. This stores all the configs of the experiments, right from the prompts to the refinement technque and the configuration of the scheduler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJCIrBKT8iko"
      },
      "outputs": [],
      "source": [
        "wandb.init(project=\"stable-diffusion-xl\", entity=\"mratanusarkar\", job_type=\"text-to-image-compel\", save_code=True)\n",
        "\n",
        "config = wandb.config\n",
        "config.stable_diffusion_checkpoint = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "config.refiner_checkpoint = \"stabilityai/stable-diffusion-xl-refiner-1.0\"\n",
        "config.offload_to_cpu = False\n",
        "config.compile_model = False\n",
        "config.prompt_1 = \"Old blind man crossing a road with a stick in hand. black glasses in eyes, hearing aid in ears. the road is filled with vehicles, traffic, and people. side view of the man, busy traffic background, realistic, 8k\"\n",
        "config.prompt_2 = \"\"\n",
        "config.negative_prompt_1 = \"static, painting, illustration, sd character, low quality, low resolution, greyscale, monochrome, nose cropped, low res, jpeg artifacts, deformed iris, deformed pupils, bad eyes, semi-realistic worst quality, bad lips, deformed mouth, deformed face, deformed fingers, deformed toes standing still, posing, deformed hand, deformed fingers, deformed face, low quality\"\n",
        "config.negative_prompt_2 = \"\"\n",
        "config.seed = None\n",
        "config.use_ensemble_of_experts = False\n",
        "config.num_inference_steps = 100\n",
        "config.num_refinement_steps = 150\n",
        "config.high_noise_fraction = 0.8 # Set explicitly only if config.use_ensemble_of_experts is True\n",
        "config.scheduler_kwargs = {\n",
        "    \"beta_end\": 0.012,\n",
        "    \"beta_schedule\": \"scaled_linear\", # one of [\"linear\", \"scaled_linear\"]\n",
        "    \"beta_start\": 0.00085,\n",
        "    \"interpolation_type\": \"linear\", # one of [\"linear\", \"log_linear\"]\n",
        "    \"num_train_timesteps\": 1000,\n",
        "    \"prediction_type\": \"epsilon\", # one of [\"epsilon\", \"sample\", \"v_prediction\"]\n",
        "    \"steps_offset\": 1,\n",
        "    \"timestep_spacing\": \"leading\", # one of [\"linspace\", \"leading\"]\n",
        "    \"trained_betas\": None,\n",
        "    \"use_karras_sigmas\": False,\n",
        "}\n",
        "config.prompt_credits = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OejepVL8ikp"
      },
      "source": [
        "We can make the experiment deterministic based on the seed specified in the experiment configs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ewjvrcg78ikp"
      },
      "outputs": [],
      "source": [
        "if config.seed is not None:\n",
        "    generator = [torch.Generator(device=\"cuda\").manual_seed(config.seed)]\n",
        "else:\n",
        "    generator = [torch.Generator(device=\"cuda\")]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZa6njKh8ikq"
      },
      "source": [
        "## Creating the Diffusion Pipelines\n",
        "\n",
        "For performing text-conditional image generation, we use the `diffusers` library to define the diffusion pipelines corresponding to the base SDXL model and the SDXL refinement model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAocHNHk8ikq"
      },
      "outputs": [],
      "source": [
        "pipe = DiffusionPipeline.from_pretrained(\n",
        "    config.stable_diffusion_checkpoint,\n",
        "    torch_dtype=torch.float16,\n",
        "    variant=\"fp16\",\n",
        "    use_safetensors=True,\n",
        "    scheduler=EulerDiscreteScheduler(**config.scheduler_kwargs),\n",
        ")\n",
        "\n",
        "if config.offload_to_cpu:\n",
        "    pipe.enable_model_cpu_offload()\n",
        "else:\n",
        "    pipe.to(\"cuda\")\n",
        "\n",
        "if config.compile_model:\n",
        "    pipe.unet = torch.compile(pipe.unet, mode=\"reduce-overhead\", fullgraph=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhxvLRH-8ikq"
      },
      "outputs": [],
      "source": [
        "if config.prompt_2 == \"\" and config.negative_prompt_2 == \"\":\n",
        "    base_compel = Compel(\n",
        "        tokenizer=[pipe.tokenizer, pipe.tokenizer_2],\n",
        "        text_encoder=[pipe.text_encoder, pipe.text_encoder_2],\n",
        "        returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n",
        "        requires_pooled=[False, True]\n",
        "    )\n",
        "\n",
        "    base_positive_prompt_embeds, base_positive_prompt_pooled = base_compel(config.prompt)\n",
        "    base_negative_prompt_embeds, base_negative_prompt_pooled = base_compel(config.negative_prompt)\n",
        "    base_positive_prompt_embeds, base_negative_prompt_embeds = base_compel.pad_conditioning_tensors_to_same_length([\n",
        "        base_positive_prompt_embeds, base_negative_prompt_embeds\n",
        "    ])\n",
        "else:\n",
        "    base_compel_1 = Compel(\n",
        "        tokenizer=pipe.tokenizer,\n",
        "        text_encoder=pipe.text_encoder,\n",
        "        returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n",
        "        requires_pooled=False,\n",
        "    )\n",
        "\n",
        "    base_positive_prompt_embeds_1 = base_compel_1(config.prompt_1)\n",
        "    base_negative_prompt_embeds_1 = base_compel_1(config.negative_prompt_1)\n",
        "\n",
        "    base_compel_2 = Compel(\n",
        "        tokenizer=pipe.tokenizer_2,\n",
        "        text_encoder=pipe.text_encoder_2,\n",
        "        returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n",
        "        requires_pooled=True,\n",
        "    )\n",
        "\n",
        "    base_positive_prompt_embeds_2, base_positive_prompt_pooled = base_compel_2(config.prompt_2)\n",
        "    base_negative_prompt_embeds_2, base_negative_prompt_pooled = base_compel_2(config.negative_prompt_2)\n",
        "\n",
        "    (\n",
        "        base_positive_prompt_embeds_2, base_negative_prompt_embeds_2\n",
        "    ) = base_compel_2.pad_conditioning_tensors_to_same_length([\n",
        "        base_positive_prompt_embeds_2, base_negative_prompt_embeds_2\n",
        "    ])\n",
        "\n",
        "    base_positive_prompt_embeds = torch.cat((base_positive_prompt_embeds_1, base_positive_prompt_embeds_2), dim=-1)\n",
        "    base_negative_prompt_embeds = torch.cat((base_negative_prompt_embeds_1, base_negative_prompt_embeds_2), dim=-1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Li_QH5cS8ikr"
      },
      "source": [
        "## Text-to-Image Generation\n",
        "\n",
        "Now, we pass the embeddings and pooled prompts to the Stable Diffusion XL pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tXgE_cJ8ikr"
      },
      "outputs": [],
      "source": [
        "image = pipe(\n",
        "    prompt_embeds=base_positive_prompt_embeds,\n",
        "    pooled_prompt_embeds=base_positive_prompt_pooled,\n",
        "    negative_prompt_embeds=base_negative_prompt_embeds,\n",
        "    negative_pooled_prompt_embeds=base_negative_prompt_pooled,\n",
        "    output_type=\"pil\",\n",
        "    num_inference_steps=config.num_inference_steps,\n",
        "    generator=generator,\n",
        ").images[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"stable_diffusion_checkpoint:\", \"\\t\", config.stable_diffusion_checkpoint)\n",
        "print(\"refiner_checkpoint:\", \"\\t\\t\", config.refiner_checkpoint)\n",
        "print(\"offload_to_cpu:\", \"\\t\\t\", config.offload_to_cpu)\n",
        "print(\"compile_model:\", \"\\t\\t\\t\", config.compile_model)\n",
        "print(\"seed:\", \"\\t\\t\\t\\t\", config.seed)\n",
        "print(\"num_inference_steps:\", \"\\t\\t\", config.num_inference_steps)\n",
        "print(\"num_refinement_steps:\", \"\\t\\t\", config.num_refinement_steps)\n",
        "print(\"high_noise_fraction:\", \"\\t\\t\", config.high_noise_fraction)\n",
        "print(\"prompt_1:\", \"\\t\\t\\t\", config.prompt_1)\n",
        "print(\"prompt_2:\", \"\\t\\t\\t\", config.prompt_2)\n",
        "print(\"negative_prompt_1:\", \"\\t\\t\", config.negative_prompt_1)\n",
        "print(\"negative_prompt_2:\", \"\\t\\t\", config.negative_prompt_2)\n",
        "\n",
        "image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orKGCF8q8ikr"
      },
      "source": [
        "## Logging the Images to Weights & Biases\n",
        "\n",
        "Now, we log the images to Weights & Biases. This enables us to:\n",
        "\n",
        "- Visualize our generations\n",
        "- Examine the generated images across different images\n",
        "- Ensure reproducibility of the experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUeyHk9q8iks"
      },
      "outputs": [],
      "source": [
        "# table = wandb.Table(columns=[\n",
        "#     \"Prompt-1\",\n",
        "#     \"Prompt-2\",\n",
        "#     \"Negative-Prompt-1\",\n",
        "#     \"Negative-Prompt-2\",\n",
        "#     \"Generated-Image\"\n",
        "# ])\n",
        "\n",
        "# image = wandb.Image(image)\n",
        "\n",
        "# table.add_data(\n",
        "#     config.prompt_1,\n",
        "#     config.prompt_2,\n",
        "#     config.negative_prompt_1,\n",
        "#     config.negative_prompt_2,\n",
        "#     image,\n",
        "# )\n",
        "# wandb.log({\n",
        "#     \"Generated-Image\": image,\n",
        "#     \"Text-to-Image\": table\n",
        "# })\n",
        "# wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
