{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eeba2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qq diffusers[\"torch\"] transformers compel wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d726c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import wandb\n",
    "from diffusers import DiffusionPipeline, EulerDiscreteScheduler\n",
    "from compel import Compel, ReturnedEmbeddingsType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cdf58f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"stable-diffusion-xl\", entity=\"mratanusarkar\", job_type=\"text-to-image-compel\", save_code=True)\n",
    "\n",
    "config = wandb.config\n",
    "config.stable_diffusion_checkpoint = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "config.refiner_checkpoint = \"stabilityai/stable-diffusion-xl-refiner-1.0\"\n",
    "config.offload_to_cpu = False\n",
    "config.compile_model = False\n",
    "config.prompt_1 = \"a diagram showing flowchart of org chart, chart, diagram---------\"\n",
    "config.prompt_2 = \"a rectangular box with 'CEO' written in it, another 2 boxes with 'president' and 'CAO' written in it connected to first box with arrows\"\n",
    "config.negative_prompt_1 = \"paiting, nature, static, sd character, low quality, low resolution, greyscale, monochrome, cropped, lowres, realistic, semi-realistic, worst quality, posing\"\n",
    "config.negative_prompt_2 = \"low-quality, photograph, painting\"\n",
    "config.seed = 42\n",
    "config.use_ensemble_of_experts = False\n",
    "config.num_inference_steps = 100\n",
    "config.num_refinement_steps = 150\n",
    "config.high_noise_fraction = 0.8 # Set explicitly only if config.use_ensemble_of_experts is True\n",
    "config.scheduler_kwargs = {\n",
    "    \"beta_end\": 0.012,\n",
    "    \"beta_schedule\": \"scaled_linear\", # one of [\"linear\", \"scaled_linear\"]\n",
    "    \"beta_start\": 0.00085,\n",
    "    \"interpolation_type\": \"linear\", # one of [\"linear\", \"log_linear\"]\n",
    "    \"num_train_timesteps\": 1000,\n",
    "    \"prediction_type\": \"epsilon\", # one of [\"epsilon\", \"sample\", \"v_prediction\"]\n",
    "    \"steps_offset\": 1,\n",
    "    \"timestep_spacing\": \"leading\", # one of [\"linspace\", \"leading\"]\n",
    "    \"trained_betas\": None,\n",
    "    \"use_karras_sigmas\": False,\n",
    "}\n",
    "config.prompt_credits = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "155b6597",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.seed is not None:\n",
    "    generator = [torch.Generator(device=\"cuda\").manual_seed(config.seed)]\n",
    "else:\n",
    "    generator = [torch.Generator(device=\"cuda\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75c3ae8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = DiffusionPipeline.from_pretrained(\n",
    "    config.stable_diffusion_checkpoint,\n",
    "    torch_dtype=torch.float16,\n",
    "    variant=\"fp16\",\n",
    "    use_safetensors=True,\n",
    "    scheduler=EulerDiscreteScheduler(**config.scheduler_kwargs),\n",
    ")\n",
    "\n",
    "if config.offload_to_cpu:\n",
    "    pipe.enable_model_cpu_offload()\n",
    "else:\n",
    "    pipe.to(\"cuda\")\n",
    "\n",
    "if config.compile_model:\n",
    "    pipe.unet = torch.compile(pipe.unet, mode=\"reduce-overhead\", fullgraph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "320ee66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.prompt_2 == \"\" and config.negative_prompt_2 == \"\":\n",
    "    base_compel = Compel(\n",
    "        tokenizer=[pipe.tokenizer, pipe.tokenizer_2],\n",
    "        text_encoder=[pipe.text_encoder, pipe.text_encoder_2],\n",
    "        returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n",
    "        requires_pooled=[False, True]\n",
    "    )\n",
    "\n",
    "    base_positive_prompt_embeds, base_positive_prompt_pooled = base_compel(config.prompt)\n",
    "    base_negative_prompt_embeds, base_negative_prompt_pooled = base_compel(config.negative_prompt)\n",
    "    base_positive_prompt_embeds, base_negative_prompt_embeds = base_compel.pad_conditioning_tensors_to_same_length([\n",
    "        base_positive_prompt_embeds, base_negative_prompt_embeds\n",
    "    ])\n",
    "else:\n",
    "    base_compel_1 = Compel(\n",
    "        tokenizer=pipe.tokenizer,\n",
    "        text_encoder=pipe.text_encoder,\n",
    "        returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n",
    "        requires_pooled=False,\n",
    "    )\n",
    "\n",
    "    base_positive_prompt_embeds_1 = base_compel_1(config.prompt_1)\n",
    "    base_negative_prompt_embeds_1 = base_compel_1(config.negative_prompt_1)\n",
    "\n",
    "    base_compel_2 = Compel(\n",
    "        tokenizer=pipe.tokenizer_2,\n",
    "        text_encoder=pipe.text_encoder_2,\n",
    "        returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n",
    "        requires_pooled=True,\n",
    "    )\n",
    "\n",
    "    base_positive_prompt_embeds_2, base_positive_prompt_pooled = base_compel_2(config.prompt_2)\n",
    "    base_negative_prompt_embeds_2, base_negative_prompt_pooled = base_compel_2(config.negative_prompt_2)\n",
    "\n",
    "    (\n",
    "        base_positive_prompt_embeds_2, base_negative_prompt_embeds_2\n",
    "    ) = base_compel_2.pad_conditioning_tensors_to_same_length([\n",
    "        base_positive_prompt_embeds_2, base_negative_prompt_embeds_2\n",
    "    ])\n",
    "\n",
    "    base_positive_prompt_embeds = torch.cat((base_positive_prompt_embeds_1, base_positive_prompt_embeds_2), dim=-1)\n",
    "    base_negative_prompt_embeds = torch.cat((base_negative_prompt_embeds_1, base_negative_prompt_embeds_2), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c92cab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = pipe(\n",
    "    prompt_embeds=base_positive_prompt_embeds,\n",
    "    pooled_prompt_embeds=base_positive_prompt_pooled,\n",
    "    negative_prompt_embeds=base_negative_prompt_embeds,\n",
    "    negative_pooled_prompt_embeds=base_negative_prompt_pooled,\n",
    "    output_type=\"pil\",\n",
    "    num_inference_steps=config.num_inference_steps,\n",
    "    generator=generator,\n",
    ").images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97d73b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = wandb.Table(columns=[\n",
    "    \"Prompt-1\",\n",
    "    \"Prompt-2\",\n",
    "    \"Negative-Prompt-1\",\n",
    "    \"Negative-Prompt-2\",\n",
    "    \"Generated-Image\"\n",
    "])\n",
    "\n",
    "image = wandb.Image(image)\n",
    "\n",
    "table.add_data(\n",
    "    config.prompt_1,\n",
    "    config.prompt_2,\n",
    "    config.negative_prompt_1,\n",
    "    config.negative_prompt_2,\n",
    "    image,\n",
    ")\n",
    "wandb.log({\n",
    "    \"Generated-Image\": image,\n",
    "    \"Text-to-Image\": table\n",
    "})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27902a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qq diffusers[\"torch\"] transformers compel wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a18cd515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import wandb\n",
    "from diffusers import DiffusionPipeline, EulerDiscreteScheduler\n",
    "from compel import Compel, ReturnedEmbeddingsType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b05ae3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/tsa2cob/Workspace/project-diffusers/diffusers-ipynbs/wandb/run-20230809_100423-p6qbvv5t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mratanusarkar/stable-diffusion-xl/runs/p6qbvv5t' target=\"_blank\">summer-yogurt-8</a></strong> to <a href='https://wandb.ai/mratanusarkar/stable-diffusion-xl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mratanusarkar/stable-diffusion-xl' target=\"_blank\">https://wandb.ai/mratanusarkar/stable-diffusion-xl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mratanusarkar/stable-diffusion-xl/runs/p6qbvv5t' target=\"_blank\">https://wandb.ai/mratanusarkar/stable-diffusion-xl/runs/p6qbvv5t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=\"stable-diffusion-xl\", entity=\"mratanusarkar\", job_type=\"text-to-image-compel\", save_code=True)\n",
    "\n",
    "config = wandb.config\n",
    "config.stable_diffusion_checkpoint = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "config.refiner_checkpoint = \"stabilityai/stable-diffusion-xl-refiner-1.0\"\n",
    "config.offload_to_cpu = False\n",
    "config.compile_model = False\n",
    "config.prompt_1 = \"a diagram showing flowchart of org chart, chart, diagram---------\"\n",
    "config.prompt_2 = \"a rectangular box with 'CEO' written in it, another 2 boxes with 'president' and 'CAO' written in it connected to first box with arrows\"\n",
    "config.negative_prompt_1 = \"paiting, nature, static, sd character, low quality, low resolution, greyscale, monochrome, cropped, lowres, realistic, semi-realistic, worst quality, posing\"\n",
    "config.negative_prompt_2 = \"low-quality, photograph, painting\"\n",
    "config.seed = 42\n",
    "config.use_ensemble_of_experts = False\n",
    "config.num_inference_steps = 100\n",
    "config.num_refinement_steps = 150\n",
    "config.high_noise_fraction = 0.8 # Set explicitly only if config.use_ensemble_of_experts is True\n",
    "config.scheduler_kwargs = {\n",
    "    \"beta_end\": 0.012,\n",
    "    \"beta_schedule\": \"scaled_linear\", # one of [\"linear\", \"scaled_linear\"]\n",
    "    \"beta_start\": 0.00085,\n",
    "    \"interpolation_type\": \"linear\", # one of [\"linear\", \"log_linear\"]\n",
    "    \"num_train_timesteps\": 1000,\n",
    "    \"prediction_type\": \"epsilon\", # one of [\"epsilon\", \"sample\", \"v_prediction\"]\n",
    "    \"steps_offset\": 1,\n",
    "    \"timestep_spacing\": \"leading\", # one of [\"linspace\", \"leading\"]\n",
    "    \"trained_betas\": None,\n",
    "    \"use_karras_sigmas\": False,\n",
    "}\n",
    "config.prompt_credits = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9516973c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.seed is not None:\n",
    "    generator = [torch.Generator(device=\"cuda\").manual_seed(config.seed)]\n",
    "else:\n",
    "    generator = [torch.Generator(device=\"cuda\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2d14c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de16fdba66c94f41bacde284727568e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = DiffusionPipeline.from_pretrained(\n",
    "    config.stable_diffusion_checkpoint,\n",
    "    torch_dtype=torch.float16,\n",
    "    variant=\"fp16\",\n",
    "    use_safetensors=True,\n",
    "    scheduler=EulerDiscreteScheduler(**config.scheduler_kwargs),\n",
    ")\n",
    "\n",
    "if config.offload_to_cpu:\n",
    "    pipe.enable_model_cpu_offload()\n",
    "else:\n",
    "    pipe.to(\"cuda\")\n",
    "\n",
    "if config.compile_model:\n",
    "    pipe.unet = torch.compile(pipe.unet, mode=\"reduce-overhead\", fullgraph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68dddaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.prompt_2 == \"\" and config.negative_prompt_2 == \"\":\n",
    "    base_compel = Compel(\n",
    "        tokenizer=[pipe.tokenizer, pipe.tokenizer_2],\n",
    "        text_encoder=[pipe.text_encoder, pipe.text_encoder_2],\n",
    "        returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n",
    "        requires_pooled=[False, True]\n",
    "    )\n",
    "\n",
    "    base_positive_prompt_embeds, base_positive_prompt_pooled = base_compel(config.prompt)\n",
    "    base_negative_prompt_embeds, base_negative_prompt_pooled = base_compel(config.negative_prompt)\n",
    "    base_positive_prompt_embeds, base_negative_prompt_embeds = base_compel.pad_conditioning_tensors_to_same_length([\n",
    "        base_positive_prompt_embeds, base_negative_prompt_embeds\n",
    "    ])\n",
    "else:\n",
    "    base_compel_1 = Compel(\n",
    "        tokenizer=pipe.tokenizer,\n",
    "        text_encoder=pipe.text_encoder,\n",
    "        returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n",
    "        requires_pooled=False,\n",
    "    )\n",
    "\n",
    "    base_positive_prompt_embeds_1 = base_compel_1(config.prompt_1)\n",
    "    base_negative_prompt_embeds_1 = base_compel_1(config.negative_prompt_1)\n",
    "\n",
    "    base_compel_2 = Compel(\n",
    "        tokenizer=pipe.tokenizer_2,\n",
    "        text_encoder=pipe.text_encoder_2,\n",
    "        returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n",
    "        requires_pooled=True,\n",
    "    )\n",
    "\n",
    "    base_positive_prompt_embeds_2, base_positive_prompt_pooled = base_compel_2(config.prompt_2)\n",
    "    base_negative_prompt_embeds_2, base_negative_prompt_pooled = base_compel_2(config.negative_prompt_2)\n",
    "\n",
    "    (\n",
    "        base_positive_prompt_embeds_2, base_negative_prompt_embeds_2\n",
    "    ) = base_compel_2.pad_conditioning_tensors_to_same_length([\n",
    "        base_positive_prompt_embeds_2, base_negative_prompt_embeds_2\n",
    "    ])\n",
    "\n",
    "    base_positive_prompt_embeds = torch.cat((base_positive_prompt_embeds_1, base_positive_prompt_embeds_2), dim=-1)\n",
    "    base_negative_prompt_embeds = torch.cat((base_negative_prompt_embeds_1, base_negative_prompt_embeds_2), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5788db3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6990fefff62a459985d3e2a4e3d78b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = pipe(\n",
    "    prompt_embeds=base_positive_prompt_embeds,\n",
    "    pooled_prompt_embeds=base_positive_prompt_pooled,\n",
    "    negative_prompt_embeds=base_negative_prompt_embeds,\n",
    "    negative_pooled_prompt_embeds=base_negative_prompt_pooled,\n",
    "    output_type=\"pil\",\n",
    "    num_inference_steps=config.num_inference_steps,\n",
    "    generator=generator,\n",
    ").images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "356a5278",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = wandb.Table(columns=[\n",
    "    \"Prompt-1\",\n",
    "    \"Prompt-2\",\n",
    "    \"Negative-Prompt-1\",\n",
    "    \"Negative-Prompt-2\",\n",
    "    \"Generated-Image\"\n",
    "])\n",
    "\n",
    "image = wandb.Image(image)\n",
    "\n",
    "table.add_data(\n",
    "    config.prompt_1,\n",
    "    config.prompt_2,\n",
    "    config.negative_prompt_1,\n",
    "    config.negative_prompt_2,\n",
    "    image,\n",
    ")\n",
    "wandb.log({\n",
    "    \"Generated-Image\": image,\n",
    "    \"Text-to-Image\": table\n",
    "})\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
