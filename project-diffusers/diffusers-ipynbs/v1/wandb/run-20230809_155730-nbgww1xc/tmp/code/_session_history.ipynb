{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6b8ac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qq diffusers[\"torch\"] transformers compel wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8313978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import wandb\n",
    "from diffusers import DiffusionPipeline, EulerDiscreteScheduler\n",
    "from compel import Compel, ReturnedEmbeddingsType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e03b3814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/tsa2cob/Workspace/project-diffusers/diffusers-ipynbs/wandb/run-20230809_155730-nbgww1xc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mratanusarkar/stable-diffusion-xl/runs/nbgww1xc' target=\"_blank\">earnest-night-17</a></strong> to <a href='https://wandb.ai/mratanusarkar/stable-diffusion-xl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mratanusarkar/stable-diffusion-xl' target=\"_blank\">https://wandb.ai/mratanusarkar/stable-diffusion-xl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mratanusarkar/stable-diffusion-xl/runs/nbgww1xc' target=\"_blank\">https://wandb.ai/mratanusarkar/stable-diffusion-xl/runs/nbgww1xc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=\"stable-diffusion-xl\", entity=\"mratanusarkar\", job_type=\"text-to-image-compel\", save_code=True)\n",
    "\n",
    "config = wandb.config\n",
    "config.stable_diffusion_checkpoint = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "config.refiner_checkpoint = \"stabilityai/stable-diffusion-xl-refiner-1.0\"\n",
    "config.offload_to_cpu = False\n",
    "config.compile_model = False\n",
    "config.prompt_1 = \"a diagram to show the composition relation between engine and car\"\n",
    "config.prompt_2 = \"the relationship between the engine and car should be demonstrated by a class diagram UML where the composition relationship shows the car composes an engine\"\n",
    "config.negative_prompt_1 = \"paiting, nature, static, sd character, low quality, low resolution, greyscale, monochrome, cropped, lowres, realistic, semi-realistic, worst quality, posing\"\n",
    "config.negative_prompt_2 = \"low-quality, photograph, painting, more than 3 box\"\n",
    "config.seed = None\n",
    "config.use_ensemble_of_experts = False\n",
    "config.num_inference_steps = 100\n",
    "config.num_refinement_steps = 150\n",
    "config.high_noise_fraction = 0.8 # Set explicitly only if config.use_ensemble_of_experts is True\n",
    "config.scheduler_kwargs = {\n",
    "    \"beta_end\": 0.012,\n",
    "    \"beta_schedule\": \"scaled_linear\", # one of [\"linear\", \"scaled_linear\"]\n",
    "    \"beta_start\": 0.00085,\n",
    "    \"interpolation_type\": \"linear\", # one of [\"linear\", \"log_linear\"]\n",
    "    \"num_train_timesteps\": 1000,\n",
    "    \"prediction_type\": \"epsilon\", # one of [\"epsilon\", \"sample\", \"v_prediction\"]\n",
    "    \"steps_offset\": 1,\n",
    "    \"timestep_spacing\": \"leading\", # one of [\"linspace\", \"leading\"]\n",
    "    \"trained_betas\": None,\n",
    "    \"use_karras_sigmas\": False,\n",
    "}\n",
    "config.prompt_credits = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50d5a727",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.seed is not None:\n",
    "    generator = [torch.Generator(device=\"cuda\").manual_seed(config.seed)]\n",
    "else:\n",
    "    generator = [torch.Generator(device=\"cuda\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72c8f9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c3f479e5364fb2b8721ecda379b86a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = DiffusionPipeline.from_pretrained(\n",
    "    config.stable_diffusion_checkpoint,\n",
    "    torch_dtype=torch.float16,\n",
    "    variant=\"fp16\",\n",
    "    use_safetensors=True,\n",
    "    scheduler=EulerDiscreteScheduler(**config.scheduler_kwargs),\n",
    ")\n",
    "\n",
    "if config.offload_to_cpu:\n",
    "    pipe.enable_model_cpu_offload()\n",
    "else:\n",
    "    pipe.to(\"cuda\")\n",
    "\n",
    "if config.compile_model:\n",
    "    pipe.unet = torch.compile(pipe.unet, mode=\"reduce-overhead\", fullgraph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "528a33f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.prompt_2 == \"\" and config.negative_prompt_2 == \"\":\n",
    "    base_compel = Compel(\n",
    "        tokenizer=[pipe.tokenizer, pipe.tokenizer_2],\n",
    "        text_encoder=[pipe.text_encoder, pipe.text_encoder_2],\n",
    "        returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n",
    "        requires_pooled=[False, True]\n",
    "    )\n",
    "\n",
    "    base_positive_prompt_embeds, base_positive_prompt_pooled = base_compel(config.prompt)\n",
    "    base_negative_prompt_embeds, base_negative_prompt_pooled = base_compel(config.negative_prompt)\n",
    "    base_positive_prompt_embeds, base_negative_prompt_embeds = base_compel.pad_conditioning_tensors_to_same_length([\n",
    "        base_positive_prompt_embeds, base_negative_prompt_embeds\n",
    "    ])\n",
    "else:\n",
    "    base_compel_1 = Compel(\n",
    "        tokenizer=pipe.tokenizer,\n",
    "        text_encoder=pipe.text_encoder,\n",
    "        returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n",
    "        requires_pooled=False,\n",
    "    )\n",
    "\n",
    "    base_positive_prompt_embeds_1 = base_compel_1(config.prompt_1)\n",
    "    base_negative_prompt_embeds_1 = base_compel_1(config.negative_prompt_1)\n",
    "\n",
    "    base_compel_2 = Compel(\n",
    "        tokenizer=pipe.tokenizer_2,\n",
    "        text_encoder=pipe.text_encoder_2,\n",
    "        returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n",
    "        requires_pooled=True,\n",
    "    )\n",
    "\n",
    "    base_positive_prompt_embeds_2, base_positive_prompt_pooled = base_compel_2(config.prompt_2)\n",
    "    base_negative_prompt_embeds_2, base_negative_prompt_pooled = base_compel_2(config.negative_prompt_2)\n",
    "\n",
    "    (\n",
    "        base_positive_prompt_embeds_2, base_negative_prompt_embeds_2\n",
    "    ) = base_compel_2.pad_conditioning_tensors_to_same_length([\n",
    "        base_positive_prompt_embeds_2, base_negative_prompt_embeds_2\n",
    "    ])\n",
    "\n",
    "    base_positive_prompt_embeds = torch.cat((base_positive_prompt_embeds_1, base_positive_prompt_embeds_2), dim=-1)\n",
    "    base_negative_prompt_embeds = torch.cat((base_negative_prompt_embeds_1, base_negative_prompt_embeds_2), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "679e7503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2397cc630df54bc5aecff0efdc465bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = pipe(\n",
    "    prompt_embeds=base_positive_prompt_embeds,\n",
    "    pooled_prompt_embeds=base_positive_prompt_pooled,\n",
    "    negative_prompt_embeds=base_negative_prompt_embeds,\n",
    "    negative_pooled_prompt_embeds=base_negative_prompt_pooled,\n",
    "    output_type=\"pil\",\n",
    "    num_inference_steps=config.num_inference_steps,\n",
    "    generator=generator,\n",
    ").images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e64bb2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=1024x1024>"
     ]
    }
   ],
   "source": [
    "print(\"stable_diffusion_checkpoint:\", \"\\t\", config.stable_diffusion_checkpoint)\n",
    "print(\"refiner_checkpoint:\", \"\\t\\t\", config.refiner_checkpoint)\n",
    "print(\"offload_to_cpu:\", \"\\t\\t\", config.offload_to_cpu)\n",
    "print(\"compile_model:\", \"\\t\\t\\t\", config.compile_model)\n",
    "print(\"seed:\", \"\\t\\t\\t\\t\", config.seed)\n",
    "print(\"num_inference_steps:\", \"\\t\\t\", config.num_inference_steps)\n",
    "print(\"num_refinement_steps:\", \"\\t\\t\", config.num_refinement_steps)\n",
    "print(\"high_noise_fraction:\", \"\\t\\t\", config.high_noise_fraction)\n",
    "print(\"prompt_1:\", \"\\t\\t\\t\", config.prompt_1)\n",
    "print(\"prompt_2:\", \"\\t\\t\\t\", config.prompt_2)\n",
    "print(\"negative_prompt_1:\", \"\\t\\t\", config.negative_prompt_1)\n",
    "print(\"negative_prompt_2:\", \"\\t\\t\", config.negative_prompt_2)\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2976529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table = wandb.Table(columns=[\n",
    "#     \"Prompt-1\",\n",
    "#     \"Prompt-2\",\n",
    "#     \"Negative-Prompt-1\",\n",
    "#     \"Negative-Prompt-2\",\n",
    "#     \"Generated-Image\"\n",
    "# ])\n",
    "\n",
    "# image = wandb.Image(image)\n",
    "\n",
    "# table.add_data(\n",
    "#     config.prompt_1,\n",
    "#     config.prompt_2,\n",
    "#     config.negative_prompt_1,\n",
    "#     config.negative_prompt_2,\n",
    "#     image,\n",
    "# )\n",
    "# wandb.log({\n",
    "#     \"Generated-Image\": image,\n",
    "#     \"Text-to-Image\": table\n",
    "# })\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d3a75f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"stable-diffusion-xl\", entity=\"mratanusarkar\", job_type=\"text-to-image-compel\", save_code=True)\n",
    "\n",
    "config = wandb.config\n",
    "config.stable_diffusion_checkpoint = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "config.refiner_checkpoint = \"stabilityai/stable-diffusion-xl-refiner-1.0\"\n",
    "config.offload_to_cpu = False\n",
    "config.compile_model = False\n",
    "config.prompt_1 = \"UML class diagram showcasing the composition relationship between 'Car' and 'Engine', where 'Car' is composed of 'Engine'. Use standard UML symbols for composition.\"\n",
    "config.prompt_2 = \"Illustrate a UML diagram where the 'Car' class has a composition relationship with the 'Engine' class, signifying that a car contains an engine.\"\n",
    "config.negative_prompt_1 = \"inheritance, aggregation relationships in the diagram.\"\n",
    "config.negative_prompt_2 = \"Avoid including any additional classes or relationships other than 'Car' and 'Engine' with the composition relationship.\"\n",
    "config.seed = None\n",
    "config.use_ensemble_of_experts = False\n",
    "config.num_inference_steps = 100\n",
    "config.num_refinement_steps = 150\n",
    "config.high_noise_fraction = 0.8 # Set explicitly only if config.use_ensemble_of_experts is True\n",
    "config.scheduler_kwargs = {\n",
    "    \"beta_end\": 0.012,\n",
    "    \"beta_schedule\": \"scaled_linear\", # one of [\"linear\", \"scaled_linear\"]\n",
    "    \"beta_start\": 0.00085,\n",
    "    \"interpolation_type\": \"linear\", # one of [\"linear\", \"log_linear\"]\n",
    "    \"num_train_timesteps\": 1000,\n",
    "    \"prediction_type\": \"epsilon\", # one of [\"epsilon\", \"sample\", \"v_prediction\"]\n",
    "    \"steps_offset\": 1,\n",
    "    \"timestep_spacing\": \"leading\", # one of [\"linspace\", \"leading\"]\n",
    "    \"trained_betas\": None,\n",
    "    \"use_karras_sigmas\": False,\n",
    "}\n",
    "config.prompt_credits = \"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
